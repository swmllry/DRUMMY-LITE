{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketWriteStream = void 0;\n\nconst stream_1 = require(\"stream\");\n\nconst bson_1 = require(\"../bson\");\n\nconst error_1 = require(\"../error\");\n\nconst utils_1 = require(\"../utils\");\n\nconst write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\n\n\nclass GridFSBucketWriteStream extends stream_1.Writable {\n  /** @internal\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   */\n  constructor(bucket, filename, options) {\n    super();\n    options = options !== null && options !== void 0 ? options : {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern; // Signals the write is all done\n\n    this.done = false;\n    this.id = options.id ? options.id : new bson_1.ObjectId(); // properly inherit the default chunksize from parent\n\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n      checkIndexes(this, () => {\n        this.bucket.s.checkedIndexes = true;\n        this.bucket.emit('index');\n      });\n    }\n  }\n\n  write(chunk, encodingOrCallback, callback) {\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    return waitForIndexes(this, () => doWrite(this, chunk, encoding, callback));\n  }\n\n  abort(callback) {\n    return (0, utils_1.maybePromise)(callback, callback => {\n      if (this.state.streamEnd) {\n        // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n        return callback(new error_1.MongoAPIError('Cannot abort a stream that has already completed'));\n      }\n\n      if (this.state.aborted) {\n        // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n        return callback(new error_1.MongoAPIError('Cannot call abort() on a stream twice'));\n      }\n\n      this.state.aborted = true;\n      this.chunks.deleteMany({\n        files_id: this.id\n      }, error => callback(error));\n    });\n  }\n\n  end(chunkOrCallback, encodingOrCallback, callback) {\n    const chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof chunkOrCallback === 'function' ? chunkOrCallback : typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    if (this.state.streamEnd || checkAborted(this, callback)) return this;\n    this.state.streamEnd = true;\n\n    if (callback) {\n      this.once(GridFSBucketWriteStream.FINISH, result => {\n        if (callback) callback(undefined, result);\n      });\n    }\n\n    if (!chunk) {\n      waitForIndexes(this, () => !!writeRemnant(this));\n      return this;\n    }\n\n    this.write(chunk, encoding, () => {\n      writeRemnant(this);\n    });\n    return this;\n  }\n\n}\n\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\n/** @event */\n\nGridFSBucketWriteStream.CLOSE = 'close';\n/** @event */\n\nGridFSBucketWriteStream.ERROR = 'error';\n/**\n * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\n * @event\n */\n\nGridFSBucketWriteStream.FINISH = 'finish';\n\nfunction __handleError(stream, error, callback) {\n  if (stream.state.errored) {\n    return;\n  }\n\n  stream.state.errored = true;\n\n  if (callback) {\n    return callback(error);\n  }\n\n  stream.emit(GridFSBucketWriteStream.ERROR, error);\n}\n\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: new bson_1.ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\n\nfunction checkChunksIndex(stream, callback) {\n  stream.chunks.listIndexes().toArray((error, indexes) => {\n    let index;\n\n    if (error) {\n      // Collection doesn't exist so create index\n      if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n        index = {\n          files_id: 1,\n          n: 1\n        };\n        stream.chunks.createIndex(index, {\n          background: false,\n          unique: true\n        }, error => {\n          if (error) {\n            return callback(error);\n          }\n\n          callback();\n        });\n        return;\n      }\n\n      return callback(error);\n    }\n\n    let hasChunksIndex = false;\n\n    if (indexes) {\n      indexes.forEach(index => {\n        if (index.key) {\n          const keys = Object.keys(index.key);\n\n          if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n            hasChunksIndex = true;\n          }\n        }\n      });\n    }\n\n    if (hasChunksIndex) {\n      callback();\n    } else {\n      index = {\n        files_id: 1,\n        n: 1\n      };\n      const writeConcernOptions = getWriteOptions(stream);\n      stream.chunks.createIndex(index, { ...writeConcernOptions,\n        background: true,\n        unique: true\n      }, callback);\n    }\n  });\n}\n\nfunction checkDone(stream, callback) {\n  if (stream.done) return true;\n\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true; // Create a new files doc\n\n    const filesDoc = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n\n    if (checkAborted(stream, callback)) {\n      return false;\n    }\n\n    stream.files.insertOne(filesDoc, getWriteOptions(stream), error => {\n      if (error) {\n        return __handleError(stream, error, callback);\n      }\n\n      stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\n      stream.emit(GridFSBucketWriteStream.CLOSE);\n    });\n    return true;\n  }\n\n  return false;\n}\n\nfunction checkIndexes(stream, callback) {\n  stream.files.findOne({}, {\n    projection: {\n      _id: 1\n    }\n  }, (error, doc) => {\n    if (error) {\n      return callback(error);\n    }\n\n    if (doc) {\n      return callback();\n    }\n\n    stream.files.listIndexes().toArray((error, indexes) => {\n      let index;\n\n      if (error) {\n        // Collection doesn't exist so create index\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n          index = {\n            filename: 1,\n            uploadDate: 1\n          };\n          stream.files.createIndex(index, {\n            background: false\n          }, error => {\n            if (error) {\n              return callback(error);\n            }\n\n            checkChunksIndex(stream, callback);\n          });\n          return;\n        }\n\n        return callback(error);\n      }\n\n      let hasFileIndex = false;\n\n      if (indexes) {\n        indexes.forEach(index => {\n          const keys = Object.keys(index.key);\n\n          if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n            hasFileIndex = true;\n          }\n        });\n      }\n\n      if (hasFileIndex) {\n        checkChunksIndex(stream, callback);\n      } else {\n        index = {\n          filename: 1,\n          uploadDate: 1\n        };\n        const writeConcernOptions = getWriteOptions(stream);\n        stream.files.createIndex(index, { ...writeConcernOptions,\n          background: false\n        }, error => {\n          if (error) {\n            return callback(error);\n          }\n\n          checkChunksIndex(stream, callback);\n        });\n      }\n    });\n  });\n}\n\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n  const ret = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, chunk, encoding, callback) {\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  stream.length += inputBuf.length; // Input is small enough to fit in our buffer\n\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    callback && callback(); // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // True means client can keep writing.\n\n    return true;\n  } // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n\n\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc;\n\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (checkAborted(stream, callback)) {\n        return false;\n      }\n\n      stream.chunks.insertOne(doc, getWriteOptions(stream), error => {\n        if (error) {\n          return __handleError(stream, error);\n        }\n\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n\n        if (!outstandingRequests) {\n          stream.emit('drain', doc);\n          callback && callback();\n          checkDone(stream);\n        }\n      });\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  } // Note that we reverse the typical semantics of write's return value\n  // to be compatible with node's `.pipe()` function.\n  // False means the client should wait for the 'drain' event.\n\n\n  return false;\n}\n\nfunction getWriteOptions(stream) {\n  const obj = {};\n\n  if (stream.writeConcern) {\n    obj.writeConcern = {\n      w: stream.writeConcern.w,\n      wtimeout: stream.writeConcern.wtimeout,\n      j: stream.writeConcern.j\n    };\n  }\n\n  return obj;\n}\n\nfunction waitForIndexes(stream, callback) {\n  if (stream.bucket.s.checkedIndexes) {\n    return callback(false);\n  }\n\n  stream.bucket.once('index', () => {\n    callback(true);\n  });\n  return true;\n}\n\nfunction writeRemnant(stream, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n\n  ++stream.state.outstandingRequests; // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant); // If the stream was aborted, do not write remnant\n\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  stream.chunks.insertOne(doc, getWriteOptions(stream), error => {\n    if (error) {\n      return __handleError(stream, error);\n    }\n\n    --stream.state.outstandingRequests;\n    checkDone(stream);\n  });\n  return true;\n}\n\nfunction checkAborted(stream, callback) {\n  if (stream.state.aborted) {\n    if (typeof callback === 'function') {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n      callback(new error_1.MongoAPIError('Stream has been aborted'));\n    }\n\n    return true;\n  }\n\n  return false;\n}","map":{"version":3,"sources":["../../src/gridfs/upload.ts"],"names":[],"mappings":";;;;;;;AAAA,MAAA,QAAA,GAAA,OAAA,CAAA,QAAA,CAAA;;AAGA,MAAA,MAAA,GAAA,OAAA,CAAA,SAAA,CAAA;;AAEA,MAAA,OAAA,GAAA,OAAA,CAAA,UAAA,CAAA;;AACA,MAAA,OAAA,GAAA,OAAA,CAAA,UAAA,CAAA;;AAEA,MAAA,eAAA,GAAA,OAAA,CAAA,oBAAA,CAAA;AA0BA;;;;;AAKG;;;AACH,MAAa,uBAAb,SAA6C,QAAA,CAAA,QAA7C,CAAqD;EA+BnD;;;;AAIG;EACH,WAAA,CAAY,MAAZ,EAAkC,QAAlC,EAAoD,OAApD,EAA4F;IAC1F;IAEA,OAAO,GAAG,OAAO,KAAA,IAAP,IAAA,OAAO,KAAA,KAAA,CAAP,GAAA,OAAA,GAAW,EAArB;IACA,KAAK,MAAL,GAAc,MAAd;IACA,KAAK,MAAL,GAAc,MAAM,CAAC,CAAP,CAAS,iBAAvB;IACA,KAAK,QAAL,GAAgB,QAAhB;IACA,KAAK,KAAL,GAAa,MAAM,CAAC,CAAP,CAAS,gBAAtB;IACA,KAAK,OAAL,GAAe,OAAf;IACA,KAAK,YAAL,GAAoB,eAAA,CAAA,YAAA,CAAa,WAAb,CAAyB,OAAzB,KAAqC,MAAM,CAAC,CAAP,CAAS,OAAT,CAAiB,YAA1E,CAT0F,CAU1F;;IACA,KAAK,IAAL,GAAY,KAAZ;IAEA,KAAK,EAAL,GAAU,OAAO,CAAC,EAAR,GAAa,OAAO,CAAC,EAArB,GAA0B,IAAI,MAAA,CAAA,QAAJ,EAApC,CAb0F,CAc1F;;IACA,KAAK,cAAL,GAAsB,OAAO,CAAC,cAAR,IAA0B,KAAK,MAAL,CAAY,CAAZ,CAAc,OAAd,CAAsB,cAAtE;IACA,KAAK,UAAL,GAAkB,MAAM,CAAC,KAAP,CAAa,KAAK,cAAlB,CAAlB;IACA,KAAK,MAAL,GAAc,CAAd;IACA,KAAK,CAAL,GAAS,CAAT;IACA,KAAK,GAAL,GAAW,CAAX;IACA,KAAK,KAAL,GAAa;MACX,SAAS,EAAE,KADA;MAEX,mBAAmB,EAAE,CAFV;MAGX,OAAO,EAAE,KAHE;MAIX,OAAO,EAAE;IAJE,CAAb;;IAOA,IAAI,CAAC,KAAK,MAAL,CAAY,CAAZ,CAAc,sBAAnB,EAA2C;MACzC,KAAK,MAAL,CAAY,CAAZ,CAAc,sBAAd,GAAuC,IAAvC;MAEA,YAAY,CAAC,IAAD,EAAO,MAAK;QACtB,KAAK,MAAL,CAAY,CAAZ,CAAc,cAAd,GAA+B,IAA/B;QACA,KAAK,MAAL,CAAY,IAAZ,CAAiB,OAAjB;MACD,CAHW,CAAZ;IAID;EACF;;EAkBQ,KAAK,CACZ,KADY,EAEZ,kBAFY,EAGZ,QAHY,EAGa;IAEzB,MAAM,QAAQ,GAAG,OAAO,kBAAP,KAA8B,UAA9B,GAA2C,SAA3C,GAAuD,kBAAxE;IACA,QAAQ,GAAG,OAAO,kBAAP,KAA8B,UAA9B,GAA2C,kBAA3C,GAAgE,QAA3E;IACA,OAAO,cAAc,CAAC,IAAD,EAAO,MAAM,OAAO,CAAC,IAAD,EAAO,KAAP,EAAc,QAAd,EAAwB,QAAxB,CAApB,CAArB;EACD;;EAWD,KAAK,CAAC,QAAD,EAA0B;IAC7B,OAAO,CAAA,GAAA,OAAA,CAAA,YAAA,EAAa,QAAb,EAAuB,QAAQ,IAAG;MACvC,IAAI,KAAK,KAAL,CAAW,SAAf,EAA0B;QACxB;QACA,OAAO,QAAQ,CAAC,IAAI,OAAA,CAAA,aAAJ,CAAkB,kDAAlB,CAAD,CAAf;MACD;;MAED,IAAI,KAAK,KAAL,CAAW,OAAf,EAAwB;QACtB;QACA,OAAO,QAAQ,CAAC,IAAI,OAAA,CAAA,aAAJ,CAAkB,uCAAlB,CAAD,CAAf;MACD;;MAED,KAAK,KAAL,CAAW,OAAX,GAAqB,IAArB;MACA,KAAK,MAAL,CAAY,UAAZ,CAAuB;QAAE,QAAQ,EAAE,KAAK;MAAjB,CAAvB,EAA8C,KAAK,IAAI,QAAQ,CAAC,KAAD,CAA/D;IACD,CAbM,CAAP;EAcD;;EAqBQ,GAAG,CACV,eADU,EAEV,kBAFU,EAGV,QAHU,EAG4B;IAEtC,MAAM,KAAK,GAAG,OAAO,eAAP,KAA2B,UAA3B,GAAwC,SAAxC,GAAoD,eAAlE;IACA,MAAM,QAAQ,GAAG,OAAO,kBAAP,KAA8B,UAA9B,GAA2C,SAA3C,GAAuD,kBAAxE;IACA,QAAQ,GACN,OAAO,eAAP,KAA2B,UAA3B,GACI,eADJ,GAEI,OAAO,kBAAP,KAA8B,UAA9B,GACA,kBADA,GAEA,QALN;IAOA,IAAI,KAAK,KAAL,CAAW,SAAX,IAAwB,YAAY,CAAC,IAAD,EAAO,QAAP,CAAxC,EAA0D,OAAO,IAAP;IAE1D,KAAK,KAAL,CAAW,SAAX,GAAuB,IAAvB;;IAEA,IAAI,QAAJ,EAAc;MACZ,KAAK,IAAL,CAAU,uBAAuB,CAAC,MAAlC,EAA2C,MAAD,IAAuB;QAC/D,IAAI,QAAJ,EAAc,QAAQ,CAAC,SAAD,EAAY,MAAZ,CAAR;MACf,CAFD;IAGD;;IAED,IAAI,CAAC,KAAL,EAAY;MACV,cAAc,CAAC,IAAD,EAAO,MAAM,CAAC,CAAC,YAAY,CAAC,IAAD,CAA3B,CAAd;MACA,OAAO,IAAP;IACD;;IAED,KAAK,KAAL,CAAW,KAAX,EAAkB,QAAlB,EAA4B,MAAK;MAC/B,YAAY,CAAC,IAAD,CAAZ;IACD,CAFD;IAIA,OAAO,IAAP;EACD;;AAlLkD;;AAArD,OAAA,CAAA,uBAAA,GAAA,uBAAA;AAqBE;;AACgB,uBAAA,CAAA,KAAA,GAAQ,OAAR;AAChB;;AACgB,uBAAA,CAAA,KAAA,GAAQ,OAAR;AAChB;;;AAGG;;AACa,uBAAA,CAAA,MAAA,GAAS,QAAT;;AAwJlB,SAAS,aAAT,CACE,MADF,EAEE,KAFF,EAGE,QAHF,EAGqB;EAEnB,IAAI,MAAM,CAAC,KAAP,CAAa,OAAjB,EAA0B;IACxB;EACD;;EACD,MAAM,CAAC,KAAP,CAAa,OAAb,GAAuB,IAAvB;;EACA,IAAI,QAAJ,EAAc;IACZ,OAAO,QAAQ,CAAC,KAAD,CAAf;EACD;;EACD,MAAM,CAAC,IAAP,CAAY,uBAAuB,CAAC,KAApC,EAA2C,KAA3C;AACD;;AAED,SAAS,cAAT,CAAwB,OAAxB,EAA2C,CAA3C,EAAsD,IAAtD,EAAkE;EAChE,OAAO;IACL,GAAG,EAAE,IAAI,MAAA,CAAA,QAAJ,EADA;IAEL,QAAQ,EAAE,OAFL;IAGL,CAHK;IAIL;EAJK,CAAP;AAMD;;AAED,SAAS,gBAAT,CAA0B,MAA1B,EAA2D,QAA3D,EAA6E;EAC3E,MAAM,CAAC,MAAP,CAAc,WAAd,GAA4B,OAA5B,CAAoC,CAAC,KAAD,EAAmB,OAAnB,KAA2C;IAC7E,IAAI,KAAJ;;IACA,IAAI,KAAJ,EAAW;MACT;MACA,IAAI,KAAK,YAAY,OAAA,CAAA,UAAjB,IAA+B,KAAK,CAAC,IAAN,KAAe,OAAA,CAAA,mBAAA,CAAoB,iBAAtE,EAAyF;QACvF,KAAK,GAAG;UAAE,QAAQ,EAAE,CAAZ;UAAe,CAAC,EAAE;QAAlB,CAAR;QACA,MAAM,CAAC,MAAP,CAAc,WAAd,CAA0B,KAA1B,EAAiC;UAAE,UAAU,EAAE,KAAd;UAAqB,MAAM,EAAE;QAA7B,CAAjC,EAAsE,KAAK,IAAG;UAC5E,IAAI,KAAJ,EAAW;YACT,OAAO,QAAQ,CAAC,KAAD,CAAf;UACD;;UAED,QAAQ;QACT,CAND;QAOA;MACD;;MACD,OAAO,QAAQ,CAAC,KAAD,CAAf;IACD;;IAED,IAAI,cAAc,GAAG,KAArB;;IACA,IAAI,OAAJ,EAAa;MACX,OAAO,CAAC,OAAR,CAAiB,KAAD,IAAoB;QAClC,IAAI,KAAK,CAAC,GAAV,EAAe;UACb,MAAM,IAAI,GAAG,MAAM,CAAC,IAAP,CAAY,KAAK,CAAC,GAAlB,CAAb;;UACA,IAAI,IAAI,CAAC,MAAL,KAAgB,CAAhB,IAAqB,KAAK,CAAC,GAAN,CAAU,QAAV,KAAuB,CAA5C,IAAiD,KAAK,CAAC,GAAN,CAAU,CAAV,KAAgB,CAArE,EAAwE;YACtE,cAAc,GAAG,IAAjB;UACD;QACF;MACF,CAPD;IAQD;;IAED,IAAI,cAAJ,EAAoB;MAClB,QAAQ;IACT,CAFD,MAEO;MACL,KAAK,GAAG;QAAE,QAAQ,EAAE,CAAZ;QAAe,CAAC,EAAE;MAAlB,CAAR;MACA,MAAM,mBAAmB,GAAG,eAAe,CAAC,MAAD,CAA3C;MAEA,MAAM,CAAC,MAAP,CAAc,WAAd,CACE,KADF,EAEE,EACE,GAAG,mBADL;QAEE,UAAU,EAAE,IAFd;QAGE,MAAM,EAAE;MAHV,CAFF,EAOE,QAPF;IASD;EACF,CA9CD;AA+CD;;AAED,SAAS,SAAT,CAAmB,MAAnB,EAAoD,QAApD,EAAuE;EACrE,IAAI,MAAM,CAAC,IAAX,EAAiB,OAAO,IAAP;;EACjB,IAAI,MAAM,CAAC,KAAP,CAAa,SAAb,IAA0B,MAAM,CAAC,KAAP,CAAa,mBAAb,KAAqC,CAA/D,IAAoE,CAAC,MAAM,CAAC,KAAP,CAAa,OAAtF,EAA+F;IAC7F;IACA,MAAM,CAAC,IAAP,GAAc,IAAd,CAF6F,CAG7F;;IACA,MAAM,QAAQ,GAAG,cAAc,CAC7B,MAAM,CAAC,EADsB,EAE7B,MAAM,CAAC,MAFsB,EAG7B,MAAM,CAAC,cAHsB,EAI7B,MAAM,CAAC,QAJsB,EAK7B,MAAM,CAAC,OAAP,CAAe,WALc,EAM7B,MAAM,CAAC,OAAP,CAAe,OANc,EAO7B,MAAM,CAAC,OAAP,CAAe,QAPc,CAA/B;;IAUA,IAAI,YAAY,CAAC,MAAD,EAAS,QAAT,CAAhB,EAAoC;MAClC,OAAO,KAAP;IACD;;IAED,MAAM,CAAC,KAAP,CAAa,SAAb,CAAuB,QAAvB,EAAiC,eAAe,CAAC,MAAD,CAAhD,EAA2D,KAAD,IAAqB;MAC7E,IAAI,KAAJ,EAAW;QACT,OAAO,aAAa,CAAC,MAAD,EAAS,KAAT,EAAgB,QAAhB,CAApB;MACD;;MACD,MAAM,CAAC,IAAP,CAAY,uBAAuB,CAAC,MAApC,EAA4C,QAA5C;MACA,MAAM,CAAC,IAAP,CAAY,uBAAuB,CAAC,KAApC;IACD,CAND;IAQA,OAAO,IAAP;EACD;;EAED,OAAO,KAAP;AACD;;AAED,SAAS,YAAT,CAAsB,MAAtB,EAAuD,QAAvD,EAAyE;EACvE,MAAM,CAAC,KAAP,CAAa,OAAb,CAAqB,EAArB,EAAyB;IAAE,UAAU,EAAE;MAAE,GAAG,EAAE;IAAP;EAAd,CAAzB,EAAqD,CAAC,KAAD,EAAQ,GAAR,KAAe;IAClE,IAAI,KAAJ,EAAW;MACT,OAAO,QAAQ,CAAC,KAAD,CAAf;IACD;;IACD,IAAI,GAAJ,EAAS;MACP,OAAO,QAAQ,EAAf;IACD;;IAED,MAAM,CAAC,KAAP,CAAa,WAAb,GAA2B,OAA3B,CAAmC,CAAC,KAAD,EAAmB,OAAnB,KAAyC;MAC1E,IAAI,KAAJ;;MACA,IAAI,KAAJ,EAAW;QACT;QACA,IAAI,KAAK,YAAY,OAAA,CAAA,UAAjB,IAA+B,KAAK,CAAC,IAAN,KAAe,OAAA,CAAA,mBAAA,CAAoB,iBAAtE,EAAyF;UACvF,KAAK,GAAG;YAAE,QAAQ,EAAE,CAAZ;YAAe,UAAU,EAAE;UAA3B,CAAR;UACA,MAAM,CAAC,KAAP,CAAa,WAAb,CAAyB,KAAzB,EAAgC;YAAE,UAAU,EAAE;UAAd,CAAhC,EAAwD,KAAD,IAAqB;YAC1E,IAAI,KAAJ,EAAW;cACT,OAAO,QAAQ,CAAC,KAAD,CAAf;YACD;;YAED,gBAAgB,CAAC,MAAD,EAAS,QAAT,CAAhB;UACD,CAND;UAOA;QACD;;QACD,OAAO,QAAQ,CAAC,KAAD,CAAf;MACD;;MAED,IAAI,YAAY,GAAG,KAAnB;;MACA,IAAI,OAAJ,EAAa;QACX,OAAO,CAAC,OAAR,CAAiB,KAAD,IAAoB;UAClC,MAAM,IAAI,GAAG,MAAM,CAAC,IAAP,CAAY,KAAK,CAAC,GAAlB,CAAb;;UACA,IAAI,IAAI,CAAC,MAAL,KAAgB,CAAhB,IAAqB,KAAK,CAAC,GAAN,CAAU,QAAV,KAAuB,CAA5C,IAAiD,KAAK,CAAC,GAAN,CAAU,UAAV,KAAyB,CAA9E,EAAiF;YAC/E,YAAY,GAAG,IAAf;UACD;QACF,CALD;MAMD;;MAED,IAAI,YAAJ,EAAkB;QAChB,gBAAgB,CAAC,MAAD,EAAS,QAAT,CAAhB;MACD,CAFD,MAEO;QACL,KAAK,GAAG;UAAE,QAAQ,EAAE,CAAZ;UAAe,UAAU,EAAE;QAA3B,CAAR;QAEA,MAAM,mBAAmB,GAAG,eAAe,CAAC,MAAD,CAA3C;QAEA,MAAM,CAAC,KAAP,CAAa,WAAb,CACE,KADF,EAEE,EACE,GAAG,mBADL;UAEE,UAAU,EAAE;QAFd,CAFF,EAMG,KAAD,IAAqB;UACnB,IAAI,KAAJ,EAAW;YACT,OAAO,QAAQ,CAAC,KAAD,CAAf;UACD;;UAED,gBAAgB,CAAC,MAAD,EAAS,QAAT,CAAhB;QACD,CAZH;MAcD;IACF,CAlDD;EAmDD,CA3DD;AA4DD;;AAED,SAAS,cAAT,CACE,GADF,EAEE,MAFF,EAGE,SAHF,EAIE,QAJF,EAKE,WALF,EAME,OANF,EAOE,QAPF,EAOqB;EAEnB,MAAM,GAAG,GAAe;IACtB,GADsB;IAEtB,MAFsB;IAGtB,SAHsB;IAItB,UAAU,EAAE,IAAI,IAAJ,EAJU;IAKtB;EALsB,CAAxB;;EAQA,IAAI,WAAJ,EAAiB;IACf,GAAG,CAAC,WAAJ,GAAkB,WAAlB;EACD;;EAED,IAAI,OAAJ,EAAa;IACX,GAAG,CAAC,OAAJ,GAAc,OAAd;EACD;;EAED,IAAI,QAAJ,EAAc;IACZ,GAAG,CAAC,QAAJ,GAAe,QAAf;EACD;;EAED,OAAO,GAAP;AACD;;AAED,SAAS,OAAT,CACE,MADF,EAEE,KAFF,EAGE,QAHF,EAIE,QAJF,EAI2B;EAEzB,IAAI,YAAY,CAAC,MAAD,EAAS,QAAT,CAAhB,EAAoC;IAClC,OAAO,KAAP;EACD;;EAED,MAAM,QAAQ,GAAG,MAAM,CAAC,QAAP,CAAgB,KAAhB,IAAyB,KAAzB,GAAiC,MAAM,CAAC,IAAP,CAAY,KAAZ,EAAmB,QAAnB,CAAlD;EAEA,MAAM,CAAC,MAAP,IAAiB,QAAQ,CAAC,MAA1B,CARyB,CAUzB;;EACA,IAAI,MAAM,CAAC,GAAP,GAAa,QAAQ,CAAC,MAAtB,GAA+B,MAAM,CAAC,cAA1C,EAA0D;IACxD,QAAQ,CAAC,IAAT,CAAc,MAAM,CAAC,UAArB,EAAiC,MAAM,CAAC,GAAxC;IACA,MAAM,CAAC,GAAP,IAAc,QAAQ,CAAC,MAAvB;IAEA,QAAQ,IAAI,QAAQ,EAApB,CAJwD,CAMxD;IACA;IACA;;IACA,OAAO,IAAP;EACD,CArBwB,CAuBzB;EACA;;;EACA,IAAI,iBAAiB,GAAG,QAAQ,CAAC,MAAjC;EACA,IAAI,cAAc,GAAW,MAAM,CAAC,cAAP,GAAwB,MAAM,CAAC,GAA5D;EACA,IAAI,SAAS,GAAG,IAAI,CAAC,GAAL,CAAS,cAAT,EAAyB,QAAQ,CAAC,MAAlC,CAAhB;EACA,IAAI,mBAAmB,GAAG,CAA1B;;EACA,OAAO,iBAAiB,GAAG,CAA3B,EAA8B;IAC5B,MAAM,WAAW,GAAG,QAAQ,CAAC,MAAT,GAAkB,iBAAtC;IACA,QAAQ,CAAC,IAAT,CAAc,MAAM,CAAC,UAArB,EAAiC,MAAM,CAAC,GAAxC,EAA6C,WAA7C,EAA0D,WAAW,GAAG,SAAxE;IACA,MAAM,CAAC,GAAP,IAAc,SAAd;IACA,cAAc,IAAI,SAAlB;IACA,IAAI,GAAJ;;IACA,IAAI,cAAc,KAAK,CAAvB,EAA0B;MACxB,GAAG,GAAG,cAAc,CAAC,MAAM,CAAC,EAAR,EAAY,MAAM,CAAC,CAAnB,EAAsB,MAAM,CAAC,IAAP,CAAY,MAAM,CAAC,UAAnB,CAAtB,CAApB;MACA,EAAE,MAAM,CAAC,KAAP,CAAa,mBAAf;MACA,EAAE,mBAAF;;MAEA,IAAI,YAAY,CAAC,MAAD,EAAS,QAAT,CAAhB,EAAoC;QAClC,OAAO,KAAP;MACD;;MAED,MAAM,CAAC,MAAP,CAAc,SAAd,CAAwB,GAAxB,EAA6B,eAAe,CAAC,MAAD,CAA5C,EAAuD,KAAD,IAAqB;QACzE,IAAI,KAAJ,EAAW;UACT,OAAO,aAAa,CAAC,MAAD,EAAS,KAAT,CAApB;QACD;;QACD,EAAE,MAAM,CAAC,KAAP,CAAa,mBAAf;QACA,EAAE,mBAAF;;QAEA,IAAI,CAAC,mBAAL,EAA0B;UACxB,MAAM,CAAC,IAAP,CAAY,OAAZ,EAAqB,GAArB;UACA,QAAQ,IAAI,QAAQ,EAApB;UACA,SAAS,CAAC,MAAD,CAAT;QACD;MACF,CAZD;MAcA,cAAc,GAAG,MAAM,CAAC,cAAxB;MACA,MAAM,CAAC,GAAP,GAAa,CAAb;MACA,EAAE,MAAM,CAAC,CAAT;IACD;;IACD,iBAAiB,IAAI,SAArB;IACA,SAAS,GAAG,IAAI,CAAC,GAAL,CAAS,cAAT,EAAyB,iBAAzB,CAAZ;EACD,CAhEwB,CAkEzB;EACA;EACA;;;EACA,OAAO,KAAP;AACD;;AAED,SAAS,eAAT,CAAyB,MAAzB,EAAwD;EACtD,MAAM,GAAG,GAAwB,EAAjC;;EACA,IAAI,MAAM,CAAC,YAAX,EAAyB;IACvB,GAAG,CAAC,YAAJ,GAAmB;MACjB,CAAC,EAAE,MAAM,CAAC,YAAP,CAAoB,CADN;MAEjB,QAAQ,EAAE,MAAM,CAAC,YAAP,CAAoB,QAFb;MAGjB,CAAC,EAAE,MAAM,CAAC,YAAP,CAAoB;IAHN,CAAnB;EAKD;;EACD,OAAO,GAAP;AACD;;AAED,SAAS,cAAT,CACE,MADF,EAEE,QAFF,EAEqC;EAEnC,IAAI,MAAM,CAAC,MAAP,CAAc,CAAd,CAAgB,cAApB,EAAoC;IAClC,OAAO,QAAQ,CAAC,KAAD,CAAf;EACD;;EAED,MAAM,CAAC,MAAP,CAAc,IAAd,CAAmB,OAAnB,EAA4B,MAAK;IAC/B,QAAQ,CAAC,IAAD,CAAR;EACD,CAFD;EAIA,OAAO,IAAP;AACD;;AAED,SAAS,YAAT,CAAsB,MAAtB,EAAuD,QAAvD,EAA0E;EACxE;EACA,IAAI,MAAM,CAAC,GAAP,KAAe,CAAnB,EAAsB;IACpB,OAAO,SAAS,CAAC,MAAD,EAAS,QAAT,CAAhB;EACD;;EAED,EAAE,MAAM,CAAC,KAAP,CAAa,mBAAf,CANwE,CAQxE;EACA;;EACA,MAAM,OAAO,GAAG,MAAM,CAAC,KAAP,CAAa,MAAM,CAAC,GAApB,CAAhB;EACA,MAAM,CAAC,UAAP,CAAkB,IAAlB,CAAuB,OAAvB,EAAgC,CAAhC,EAAmC,CAAnC,EAAsC,MAAM,CAAC,GAA7C;EACA,MAAM,GAAG,GAAG,cAAc,CAAC,MAAM,CAAC,EAAR,EAAY,MAAM,CAAC,CAAnB,EAAsB,OAAtB,CAA1B,CAZwE,CAcxE;;EACA,IAAI,YAAY,CAAC,MAAD,EAAS,QAAT,CAAhB,EAAoC;IAClC,OAAO,KAAP;EACD;;EAED,MAAM,CAAC,MAAP,CAAc,SAAd,CAAwB,GAAxB,EAA6B,eAAe,CAAC,MAAD,CAA5C,EAAuD,KAAD,IAAqB;IACzE,IAAI,KAAJ,EAAW;MACT,OAAO,aAAa,CAAC,MAAD,EAAS,KAAT,CAApB;IACD;;IACD,EAAE,MAAM,CAAC,KAAP,CAAa,mBAAf;IACA,SAAS,CAAC,MAAD,CAAT;EACD,CAND;EAOA,OAAO,IAAP;AACD;;AAED,SAAS,YAAT,CAAsB,MAAtB,EAAuD,QAAvD,EAAgF;EAC9E,IAAI,MAAM,CAAC,KAAP,CAAa,OAAjB,EAA0B;IACxB,IAAI,OAAO,QAAP,KAAoB,UAAxB,EAAoC;MAClC;MACA,QAAQ,CAAC,IAAI,OAAA,CAAA,aAAJ,CAAkB,yBAAlB,CAAD,CAAR;IACD;;IACD,OAAO,IAAP;EACD;;EACD,OAAO,KAAP;AACD","sourceRoot":"","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.GridFSBucketWriteStream = void 0;\nconst stream_1 = require(\"stream\");\nconst bson_1 = require(\"../bson\");\nconst error_1 = require(\"../error\");\nconst utils_1 = require(\"../utils\");\nconst write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nclass GridFSBucketWriteStream extends stream_1.Writable {\n    /** @internal\n     * @param bucket - Handle for this stream's corresponding bucket\n     * @param filename - The value of the 'filename' key in the files doc\n     * @param options - Optional settings.\n     */\n    constructor(bucket, filename, options) {\n        super();\n        options = options !== null && options !== void 0 ? options : {};\n        this.bucket = bucket;\n        this.chunks = bucket.s._chunksCollection;\n        this.filename = filename;\n        this.files = bucket.s._filesCollection;\n        this.options = options;\n        this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n        // Signals the write is all done\n        this.done = false;\n        this.id = options.id ? options.id : new bson_1.ObjectId();\n        // properly inherit the default chunksize from parent\n        this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n        this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n        this.length = 0;\n        this.n = 0;\n        this.pos = 0;\n        this.state = {\n            streamEnd: false,\n            outstandingRequests: 0,\n            errored: false,\n            aborted: false\n        };\n        if (!this.bucket.s.calledOpenUploadStream) {\n            this.bucket.s.calledOpenUploadStream = true;\n            checkIndexes(this, () => {\n                this.bucket.s.checkedIndexes = true;\n                this.bucket.emit('index');\n            });\n        }\n    }\n    write(chunk, encodingOrCallback, callback) {\n        const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n        callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n        return waitForIndexes(this, () => doWrite(this, chunk, encoding, callback));\n    }\n    abort(callback) {\n        return (0, utils_1.maybePromise)(callback, callback => {\n            if (this.state.streamEnd) {\n                // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n                return callback(new error_1.MongoAPIError('Cannot abort a stream that has already completed'));\n            }\n            if (this.state.aborted) {\n                // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n                return callback(new error_1.MongoAPIError('Cannot call abort() on a stream twice'));\n            }\n            this.state.aborted = true;\n            this.chunks.deleteMany({ files_id: this.id }, error => callback(error));\n        });\n    }\n    end(chunkOrCallback, encodingOrCallback, callback) {\n        const chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\n        const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n        callback =\n            typeof chunkOrCallback === 'function'\n                ? chunkOrCallback\n                : typeof encodingOrCallback === 'function'\n                    ? encodingOrCallback\n                    : callback;\n        if (this.state.streamEnd || checkAborted(this, callback))\n            return this;\n        this.state.streamEnd = true;\n        if (callback) {\n            this.once(GridFSBucketWriteStream.FINISH, (result) => {\n                if (callback)\n                    callback(undefined, result);\n            });\n        }\n        if (!chunk) {\n            waitForIndexes(this, () => !!writeRemnant(this));\n            return this;\n        }\n        this.write(chunk, encoding, () => {\n            writeRemnant(this);\n        });\n        return this;\n    }\n}\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\n/** @event */\nGridFSBucketWriteStream.CLOSE = 'close';\n/** @event */\nGridFSBucketWriteStream.ERROR = 'error';\n/**\n * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\n * @event\n */\nGridFSBucketWriteStream.FINISH = 'finish';\nfunction __handleError(stream, error, callback) {\n    if (stream.state.errored) {\n        return;\n    }\n    stream.state.errored = true;\n    if (callback) {\n        return callback(error);\n    }\n    stream.emit(GridFSBucketWriteStream.ERROR, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n    return {\n        _id: new bson_1.ObjectId(),\n        files_id: filesId,\n        n,\n        data\n    };\n}\nfunction checkChunksIndex(stream, callback) {\n    stream.chunks.listIndexes().toArray((error, indexes) => {\n        let index;\n        if (error) {\n            // Collection doesn't exist so create index\n            if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n                index = { files_id: 1, n: 1 };\n                stream.chunks.createIndex(index, { background: false, unique: true }, error => {\n                    if (error) {\n                        return callback(error);\n                    }\n                    callback();\n                });\n                return;\n            }\n            return callback(error);\n        }\n        let hasChunksIndex = false;\n        if (indexes) {\n            indexes.forEach((index) => {\n                if (index.key) {\n                    const keys = Object.keys(index.key);\n                    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n                        hasChunksIndex = true;\n                    }\n                }\n            });\n        }\n        if (hasChunksIndex) {\n            callback();\n        }\n        else {\n            index = { files_id: 1, n: 1 };\n            const writeConcernOptions = getWriteOptions(stream);\n            stream.chunks.createIndex(index, {\n                ...writeConcernOptions,\n                background: true,\n                unique: true\n            }, callback);\n        }\n    });\n}\nfunction checkDone(stream, callback) {\n    if (stream.done)\n        return true;\n    if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n        // Set done so we do not trigger duplicate createFilesDoc\n        stream.done = true;\n        // Create a new files doc\n        const filesDoc = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n        if (checkAborted(stream, callback)) {\n            return false;\n        }\n        stream.files.insertOne(filesDoc, getWriteOptions(stream), (error) => {\n            if (error) {\n                return __handleError(stream, error, callback);\n            }\n            stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\n            stream.emit(GridFSBucketWriteStream.CLOSE);\n        });\n        return true;\n    }\n    return false;\n}\nfunction checkIndexes(stream, callback) {\n    stream.files.findOne({}, { projection: { _id: 1 } }, (error, doc) => {\n        if (error) {\n            return callback(error);\n        }\n        if (doc) {\n            return callback();\n        }\n        stream.files.listIndexes().toArray((error, indexes) => {\n            let index;\n            if (error) {\n                // Collection doesn't exist so create index\n                if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n                    index = { filename: 1, uploadDate: 1 };\n                    stream.files.createIndex(index, { background: false }, (error) => {\n                        if (error) {\n                            return callback(error);\n                        }\n                        checkChunksIndex(stream, callback);\n                    });\n                    return;\n                }\n                return callback(error);\n            }\n            let hasFileIndex = false;\n            if (indexes) {\n                indexes.forEach((index) => {\n                    const keys = Object.keys(index.key);\n                    if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n                        hasFileIndex = true;\n                    }\n                });\n            }\n            if (hasFileIndex) {\n                checkChunksIndex(stream, callback);\n            }\n            else {\n                index = { filename: 1, uploadDate: 1 };\n                const writeConcernOptions = getWriteOptions(stream);\n                stream.files.createIndex(index, {\n                    ...writeConcernOptions,\n                    background: false\n                }, (error) => {\n                    if (error) {\n                        return callback(error);\n                    }\n                    checkChunksIndex(stream, callback);\n                });\n            }\n        });\n    });\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n    const ret = {\n        _id,\n        length,\n        chunkSize,\n        uploadDate: new Date(),\n        filename\n    };\n    if (contentType) {\n        ret.contentType = contentType;\n    }\n    if (aliases) {\n        ret.aliases = aliases;\n    }\n    if (metadata) {\n        ret.metadata = metadata;\n    }\n    return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n    if (checkAborted(stream, callback)) {\n        return false;\n    }\n    const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n    stream.length += inputBuf.length;\n    // Input is small enough to fit in our buffer\n    if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n        inputBuf.copy(stream.bufToStore, stream.pos);\n        stream.pos += inputBuf.length;\n        callback && callback();\n        // Note that we reverse the typical semantics of write's return value\n        // to be compatible with node's `.pipe()` function.\n        // True means client can keep writing.\n        return true;\n    }\n    // Otherwise, buffer is too big for current chunk, so we need to flush\n    // to MongoDB.\n    let inputBufRemaining = inputBuf.length;\n    let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n    let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n    let outstandingRequests = 0;\n    while (inputBufRemaining > 0) {\n        const inputBufPos = inputBuf.length - inputBufRemaining;\n        inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n        stream.pos += numToCopy;\n        spaceRemaining -= numToCopy;\n        let doc;\n        if (spaceRemaining === 0) {\n            doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n            ++stream.state.outstandingRequests;\n            ++outstandingRequests;\n            if (checkAborted(stream, callback)) {\n                return false;\n            }\n            stream.chunks.insertOne(doc, getWriteOptions(stream), (error) => {\n                if (error) {\n                    return __handleError(stream, error);\n                }\n                --stream.state.outstandingRequests;\n                --outstandingRequests;\n                if (!outstandingRequests) {\n                    stream.emit('drain', doc);\n                    callback && callback();\n                    checkDone(stream);\n                }\n            });\n            spaceRemaining = stream.chunkSizeBytes;\n            stream.pos = 0;\n            ++stream.n;\n        }\n        inputBufRemaining -= numToCopy;\n        numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n    }\n    // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // False means the client should wait for the 'drain' event.\n    return false;\n}\nfunction getWriteOptions(stream) {\n    const obj = {};\n    if (stream.writeConcern) {\n        obj.writeConcern = {\n            w: stream.writeConcern.w,\n            wtimeout: stream.writeConcern.wtimeout,\n            j: stream.writeConcern.j\n        };\n    }\n    return obj;\n}\nfunction waitForIndexes(stream, callback) {\n    if (stream.bucket.s.checkedIndexes) {\n        return callback(false);\n    }\n    stream.bucket.once('index', () => {\n        callback(true);\n    });\n    return true;\n}\nfunction writeRemnant(stream, callback) {\n    // Buffer is empty, so don't bother to insert\n    if (stream.pos === 0) {\n        return checkDone(stream, callback);\n    }\n    ++stream.state.outstandingRequests;\n    // Create a new buffer to make sure the buffer isn't bigger than it needs\n    // to be.\n    const remnant = Buffer.alloc(stream.pos);\n    stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n    const doc = createChunkDoc(stream.id, stream.n, remnant);\n    // If the stream was aborted, do not write remnant\n    if (checkAborted(stream, callback)) {\n        return false;\n    }\n    stream.chunks.insertOne(doc, getWriteOptions(stream), (error) => {\n        if (error) {\n            return __handleError(stream, error);\n        }\n        --stream.state.outstandingRequests;\n        checkDone(stream);\n    });\n    return true;\n}\nfunction checkAborted(stream, callback) {\n    if (stream.state.aborted) {\n        if (typeof callback === 'function') {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n            callback(new error_1.MongoAPIError('Stream has been aborted'));\n        }\n        return true;\n    }\n    return false;\n}\n//# sourceMappingURL=upload.js.map"]},"metadata":{},"sourceType":"script"}